{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUeqRfKUEreO"
      },
      "source": [
        "**LetsGrowMore(LGMVIP)- \"DATA SCIENCE INTERN \"**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-yzTl2oErI0"
      },
      "source": [
        "**LGMVIP April-22**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De4IM9p9ErFb"
      },
      "source": [
        "**AUTHOR -SUYOG PATIL**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-quMfiLErCp"
      },
      "source": [
        "**ADVANCED LEVEL TASK**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4y9q0yvErAM"
      },
      "source": [
        "**TASK 8 : Next Word Prediction**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jI-kexP_q2Lt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from nltk.tokenize import RegexpTokenizer \n",
        "from keras.models import Sequential,load_model\n",
        "from keras.layers import LSTM \n",
        "from keras.layers import Dense ,Activation\n",
        "from tensorflow.keras.optimizers import RMSprop \n",
        "import matplotlib.pyplot as plt \n",
        "import pickle \n",
        "import heapq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_47VoxUzr3bO",
        "outputId": "f1c4f862-d24a-46b6-fd29-c11f8ee75dcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corpus length : 581888\n"
          ]
        }
      ],
      "source": [
        "text=open(r'1661-0.txt','r',encoding='utf-8').read().lower()\n",
        "print(\"corpus length :\",len(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hESoMMQcsgRs"
      },
      "outputs": [],
      "source": [
        "tokenizer=RegexpTokenizer(r'\\w+')\n",
        "words =tokenizer.tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9K7Tii-RyYlP"
      },
      "outputs": [],
      "source": [
        "unique_words=np.unique(words)\n",
        "unique_words_index=dict((c,i) for i ,c in enumerate(unique_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GebaIe3LzDPJ",
        "outputId": "286c8603-04ca-45a3-941e-debd17dd7d20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['project', 'gutenberg', 's', 'the', 'adventures']\n",
            "of\n"
          ]
        }
      ],
      "source": [
        "WORD_LENGTH=5\n",
        "prev_words=[]\n",
        "next_words=[]\n",
        "for i in range(len(words)-WORD_LENGTH):\n",
        "  prev_words.append(words[i:i+WORD_LENGTH])\n",
        "  next_words.append(words[i+WORD_LENGTH])\n",
        "print(prev_words[0])\n",
        "print(next_words[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UbSX5Cur0Sut"
      },
      "outputs": [],
      "source": [
        "X=np.zeros((len(prev_words),WORD_LENGTH,len(unique_words)),dtype=bool)\n",
        "Y=np.zeros((len(next_words),len(unique_words)),dtype=bool)\n",
        "for i ,each_words in enumerate(prev_words):\n",
        "  for j,each_words in enumerate(each_words):\n",
        "    X[i,j,unique_words_index[each_words]]=1\n",
        "  Y[i,unique_words_index[next_words[i]]]=1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I05MXw4Z2Dyy",
        "outputId": "414cb199-d4ca-45fa-b6ae-b7b2567a3424"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[False False False ... False False False]\n"
          ]
        }
      ],
      "source": [
        "print((X[0][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aH8dJDKL2vgT"
      },
      "outputs": [],
      "source": [
        "model=Sequential()\n",
        "model.add(LSTM(128,input_shape=(WORD_LENGTH,len(unique_words))))\n",
        "model.add(Dense(len(unique_words)))\n",
        "model.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKFtnNpi3bts",
        "outputId": "9181c52d-e142-460b-b406-eb033c0e6ca3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "811/811 [==============================] - 259s 316ms/step - loss: 6.0200 - accuracy: 0.1060 - val_loss: 7.0609 - val_accuracy: 0.1003\n",
            "Epoch 2/2\n",
            "811/811 [==============================] - 254s 313ms/step - loss: 5.7809 - accuracy: 0.1454 - val_loss: 7.8702 - val_accuracy: 0.1020\n"
          ]
        }
      ],
      "source": [
        "optimizer=RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=[\"accuracy\"])\n",
        "history=model.fit(X,Y,validation_split=0.05,batch_size=128,epochs=2,shuffle=True).history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "foST70S74Zmo"
      },
      "outputs": [],
      "source": [
        "model.save('keras_next_word_model.h5')\n",
        "pickle.dump(history,open('history.p','wb'))\n",
        "model=load_model('keras_next_word_model.h5')\n",
        "history=pickle.load(open('history.p','rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJP-rTYu5HjP",
        "outputId": "03037896-b7c9-4754-dca9-945cd751238c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "how\n",
            "are\n",
            "you\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def prepare_input(text):\n",
        "  x=np.zeros((1,WORD_LENGTH,len(unique_words)))\n",
        "  for t, word in enumerate(text.split()):\n",
        "    print(word)\n",
        "    x[0,t,unique_words_index[word]]=1\n",
        "  return x\n",
        "prepare_input(\"How are you \".lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "etEhMZFU6HIJ"
      },
      "outputs": [],
      "source": [
        "def sample(preds,top_n=3):\n",
        "  preds=np.asarray(preds).astype(\"float64\")\n",
        "  preds=np.log(preds)\n",
        "  exp_preds=np.exp(preds)\n",
        "  preds=exp_preds / np.sum(exp_preds)\n",
        "\n",
        "  return heapq.nlargest(top_n, range(len(preds)),preds.take)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yowfvqp774Yt"
      },
      "outputs": [],
      "source": [
        "def predict_completions(text,n=3):\n",
        "  if text==\"\":\n",
        "    return('0')\n",
        "  x=prepare_input(text)\n",
        "  preds=model.predict(X,verbose=0)[0]\n",
        "  next_indices=sample(preds,n)\n",
        "  return [unique_words[inx] for idx in next_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpDNPm4o8pTI",
        "outputId": "d589ce7b-6ebf-43d4-8ae0-e36c7f22e43c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "correct sentence :  Do your work by your own instead of depending on someone \n",
            "Sequence :  do your work by your\n",
            "do\n",
            "your\n",
            "work\n",
            "by\n",
            "your\n"
          ]
        }
      ],
      "source": [
        "q=\"Do your work by your own instead of depending on someone \"\n",
        "print(\"correct sentence : \",q)\n",
        "seq=\" \".join(tokenizer.tokenize(q.lower())[0:5])\n",
        "print(\"Sequence : \",seq)\n",
        "print(\"Next possible words :\",predict_completions(seq,5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUBESub0Bb5O"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "task8.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
